{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('30_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = pd.read_csv('mydata_for_model.csv', usecols = ['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_OOT = date[date['date']>=\"2016-11-01\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_tt = date[(date['date']<\"2016-11-01\")&(date['date']>'2016-01-14')].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "833507 38511\n"
     ]
    }
   ],
   "source": [
    "print(i_OOT[0], i_tt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = data.iloc[:,:-1].columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_use = pd.DataFrame(columns = ['Score', 'variable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_use['variable'] = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>fulladdress_count_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>address_count_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>fulladdress_pct_increase_0_to_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>fulladdress_count_0_by_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>address_count_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>fulladdress_count_0_by_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>fulladdress_pct_increase_0_to_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>address_count_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>fulladdress_count_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>fulladdress_homephone_count_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>fulladdress_homephone_day_since</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ssn_dob_day_since</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>name_dob_day_since</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ssn_name_dob_day_since</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ssn_name_dob_count_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>name_dob_count_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ssn_firstname_count_60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>fulladdress_homephone_count_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>name_dob_count_60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ssn_firstname_count_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>name_dob_count_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ssn_name_dob_count_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ssn_firstname_count_0_by_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ssn_firstname_pct_increase_0_to_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ssn_lastname_count_0_by_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>fulladdress_homephone_pct_increase_0_to_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>fulladdress_homephone_count_0_by_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>address_pct_increase_1_to_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>dob_count_wSame_homephone_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>name_count_wSame_homephone_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>fraud_label</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                                    variable\n",
       "0    NaN                        fulladdress_count_30\n",
       "1    NaN                            address_count_14\n",
       "2    NaN            fulladdress_pct_increase_0_to_30\n",
       "3    NaN                   fulladdress_count_0_by_30\n",
       "4    NaN                             address_count_3\n",
       "5    NaN                    fulladdress_count_0_by_7\n",
       "6    NaN             fulladdress_pct_increase_0_to_7\n",
       "7    NaN                             address_count_1\n",
       "8    NaN                         fulladdress_count_1\n",
       "9    NaN              fulladdress_homephone_count_30\n",
       "10   NaN             fulladdress_homephone_day_since\n",
       "11   NaN                           ssn_dob_day_since\n",
       "12   NaN                          name_dob_day_since\n",
       "13   NaN                      ssn_name_dob_day_since\n",
       "14   NaN                       ssn_name_dob_count_30\n",
       "15   NaN                           name_dob_count_30\n",
       "16   NaN                      ssn_firstname_count_60\n",
       "17   NaN              fulladdress_homephone_count_14\n",
       "18   NaN                           name_dob_count_60\n",
       "19   NaN                      ssn_firstname_count_14\n",
       "20   NaN                           name_dob_count_14\n",
       "21   NaN                       ssn_name_dob_count_14\n",
       "22   NaN                 ssn_firstname_count_0_by_30\n",
       "23   NaN          ssn_firstname_pct_increase_0_to_30\n",
       "24   NaN                  ssn_lastname_count_0_by_30\n",
       "25   NaN  fulladdress_homephone_pct_increase_0_to_30\n",
       "26   NaN         fulladdress_homephone_count_0_by_30\n",
       "27   NaN                address_pct_increase_1_to_14\n",
       "28   NaN                 dob_count_wSame_homephone_7\n",
       "29   NaN                name_count_wSame_homephone_7\n",
       "30   NaN                                 fraud_label"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OOT_data = data[data['date']>=\"2016-11-01\"]\n",
    "OOT_data = data.loc[i_OOT,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ttdata = data[data['date']<\"2016-11-01\"]\n",
    "ttdata = data.loc[i_tt,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X = ttdata.iloc[:,:-1]\n",
    "y = ttdata['fraud_label']\n",
    "OOTX = OOT_data.iloc[:,:-1]\n",
    "OOTy = OOT_data['fraud_label']\n",
    "ss.fit(X)\n",
    "X = pd.DataFrame(data = ss.transform(X), columns = cols)\n",
    "OOTX = pd.DataFrame(data = ss.transform(OOTX), columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FDR(y_pred, y_true, p):\n",
    "    y = pd.DataFrame({\"yp\":y_pred, \"yt\":y_true})\n",
    "    y = y.sort_values(by=['yp'], ascending = False)\n",
    "    nrows = int(round(len(y)*p))\n",
    "    tot = y['yt'].sum()\n",
    "    rt = sum(y.iloc[:nrows,1])/tot\n",
    "    return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "numlist = [20, 20, 30, 30]\n",
    "mflist = [10, 5, 10, 5]\n",
    "RFtrain = []\n",
    "RFtest = []\n",
    "RFOOT = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20 variables, select 10 features, FDR at 3% in training data is 0.5528210498756382\n",
      "With 20 variables, select 10 features, FDR at 3% in test data is 0.5271640239147387\n",
      "With 20 variables, select 10 features, FDR at 3% in OOT data is 0.5125733445096395\n",
      "With 20 variables, select 5 features, FDR at 3% in training data is 0.5520356067548109\n",
      "With 20 variables, select 5 features, FDR at 3% in test data is 0.5269040811021575\n",
      "With 20 variables, select 5 features, FDR at 3% in OOT data is 0.5129924559932942\n",
      "With 30 variables, select 10 features, FDR at 3% in training data is 0.5989003796308418\n",
      "With 30 variables, select 10 features, FDR at 3% in test data is 0.5760332726800104\n",
      "With 30 variables, select 10 features, FDR at 3% in OOT data is 0.5549036043587594\n",
      "With 30 variables, select 5 features, FDR at 3% in training data is 0.5975913077627962\n",
      "With 30 variables, select 5 features, FDR at 3% in test data is 0.5760332726800104\n",
      "With 30 variables, select 5 features, FDR at 3% in OOT data is 0.557837384744342\n"
     ]
    }
   ],
   "source": [
    "for num,mf in zip(numlist, mflist):\n",
    "    col_to_use = list(var_use.iloc[:num,1].values)\n",
    "    rf = RandomForestClassifier(n_estimators = 10, min_samples_leaf = 3, max_features = mf)\n",
    "    rf.fit(X_train[col_to_use], y_train)\n",
    "    RFtrain.append(FDR(pd.DataFrame(rf.predict_proba(X_train[col_to_use].values))[1].values, y_train.values, 0.03))\n",
    "    RFtest.append(FDR(pd.DataFrame(rf.predict_proba(X_test[col_to_use].values))[1].values, y_test.values, 0.03))\n",
    "    RFOOT.append(FDR(pd.DataFrame(rf.predict_proba(OOTX[col_to_use].values))[1].values, OOTy.values, 0.03))\n",
    "    print(f'With {num} variables, select {mf} features, FDR at 3% in training data is {RFtrain[-1]}')\n",
    "    print(f'With {num} variables, select {mf} features, FDR at 3% in test data is {RFtest[-1]}')\n",
    "    print(f'With {num} variables, select {mf} features, FDR at 3% in OOT data is {RFOOT[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntlist = [10, 20, 50, 100, 200, 10, 20, 50, 100, 200]\n",
    "mflist = [5,5,5,5,5,10,10,10,10,10]\n",
    "RFtrain2 = []\n",
    "RFtest2 = []\n",
    "RFOOT2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 10 trees, select 5 features, FDR at 3% in training data is 0.5975913077627962\n",
      "With 10 trees, select 5 features, FDR at 3% in test data is 0.5770730439303353\n",
      "With 10 trees, select 5 features, FDR at 3% in OOT data is 0.5565800502933781\n",
      "With 20 trees, select 5 features, FDR at 3% in training data is 0.5979840293232098\n",
      "With 20 trees, select 5 features, FDR at 3% in test data is 0.5749935014296854\n",
      "With 20 trees, select 5 features, FDR at 3% in OOT data is 0.5582564962279967\n",
      "With 50 trees, select 5 features, FDR at 3% in training data is 0.5986385652572326\n",
      "With 50 trees, select 5 features, FDR at 3% in test data is 0.5760332726800104\n",
      "With 50 trees, select 5 features, FDR at 3% in OOT data is 0.5574182732606874\n",
      "With 100 trees, select 5 features, FDR at 3% in training data is 0.5987694724440372\n",
      "With 100 trees, select 5 features, FDR at 3% in test data is 0.577852872368079\n",
      "With 100 trees, select 5 features, FDR at 3% in OOT data is 0.5586756077116513\n",
      "With 200 trees, select 5 features, FDR at 3% in training data is 0.5987694724440372\n",
      "With 200 trees, select 5 features, FDR at 3% in test data is 0.5765531583051728\n",
      "With 200 trees, select 5 features, FDR at 3% in OOT data is 0.5586756077116513\n",
      "With 10 trees, select 10 features, FDR at 3% in training data is 0.5990312868176463\n",
      "With 10 trees, select 10 features, FDR at 3% in test data is 0.5773329867429166\n",
      "With 10 trees, select 10 features, FDR at 3% in OOT data is 0.5557418273260687\n",
      "With 20 trees, select 10 features, FDR at 3% in training data is 0.5992931011912555\n",
      "With 20 trees, select 10 features, FDR at 3% in test data is 0.5762932154925916\n",
      "With 20 trees, select 10 features, FDR at 3% in OOT data is 0.5553227158424141\n",
      "With 50 trees, select 10 features, FDR at 3% in training data is 0.5995549155648645\n",
      "With 50 trees, select 10 features, FDR at 3% in test data is 0.5775929295554978\n",
      "With 50 trees, select 10 features, FDR at 3% in OOT data is 0.5565800502933781\n",
      "With 100 trees, select 10 features, FDR at 3% in training data is 0.599685822751669\n",
      "With 100 trees, select 10 features, FDR at 3% in test data is 0.5770730439303353\n",
      "With 100 trees, select 10 features, FDR at 3% in OOT data is 0.5574182732606874\n",
      "With 200 trees, select 10 features, FDR at 3% in training data is 0.5998167299384736\n",
      "With 200 trees, select 10 features, FDR at 3% in test data is 0.5762932154925916\n",
      "With 200 trees, select 10 features, FDR at 3% in OOT data is 0.5565800502933781\n"
     ]
    }
   ],
   "source": [
    "for nt,mf in zip(ntlist, mflist):\n",
    "    col_to_use = list(var_use.iloc[:30,1].values)\n",
    "    rf = RandomForestClassifier(n_estimators = nt, min_samples_leaf = 3, max_features = mf)\n",
    "    rf.fit(X_train[col_to_use], y_train)\n",
    "    RFtrain2.append(FDR(pd.DataFrame(rf.predict_proba(X_train[col_to_use].values))[1].values, y_train.values, 0.03))\n",
    "    RFtest2.append(FDR(pd.DataFrame(rf.predict_proba(X_test[col_to_use].values))[1].values, y_test.values, 0.03))\n",
    "    RFOOT2.append(FDR(pd.DataFrame(rf.predict_proba(OOTX[col_to_use].values))[1].values, OOTy.values, 0.03))\n",
    "    print(f'With {nt} trees, select {mf} features, FDR at 3% in training data is {RFtrain2[-1]}')\n",
    "    print(f'With {nt} trees, select {mf} features, FDR at 3% in test data is {RFtest2[-1]}')\n",
    "    print(f'With {nt} trees, select {mf} features, FDR at 3% in OOT data is {RFOOT2[-1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
