{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T13:40:48.912971Z",
     "start_time": "2021-03-23T13:40:48.877068Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "stdsc = StandardScaler()\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T02:16:50.267009Z",
     "start_time": "2021-03-21T02:16:46.874351Z"
    }
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('30_features-1.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T02:18:08.715089Z",
     "start_time": "2021-03-21T02:18:08.639155Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fulladdress_count_30</th>\n",
       "      <th>address_count_14</th>\n",
       "      <th>fulladdress_pct_increase_0_to_30</th>\n",
       "      <th>fulladdress_count_0_by_30</th>\n",
       "      <th>address_count_3</th>\n",
       "      <th>fulladdress_count_0_by_7</th>\n",
       "      <th>fulladdress_pct_increase_0_to_7</th>\n",
       "      <th>address_count_1</th>\n",
       "      <th>fulladdress_count_1</th>\n",
       "      <th>fulladdress_homephone_count_30</th>\n",
       "      <th>...</th>\n",
       "      <th>ssn_name_dob_count_14</th>\n",
       "      <th>ssn_firstname_count_0_by_30</th>\n",
       "      <th>ssn_firstname_pct_increase_0_to_30</th>\n",
       "      <th>ssn_lastname_count_0_by_30</th>\n",
       "      <th>fulladdress_homephone_pct_increase_0_to_30</th>\n",
       "      <th>fulladdress_homephone_count_0_by_30</th>\n",
       "      <th>address_pct_increase_1_to_14</th>\n",
       "      <th>dob_count_wSame_homephone_7</th>\n",
       "      <th>name_count_wSame_homephone_7</th>\n",
       "      <th>fraud_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fulladdress_count_30  address_count_14  fulladdress_pct_increase_0_to_30  \\\n",
       "0                     1                 1                               0.0   \n",
       "1                     1                 1                               0.0   \n",
       "2                     1                 1                               0.0   \n",
       "3                     1                 1                               0.0   \n",
       "4                     1                 1                               0.0   \n",
       "\n",
       "   fulladdress_count_0_by_30  address_count_3  fulladdress_count_0_by_7  \\\n",
       "0                       30.0                1                       7.0   \n",
       "1                       30.0                1                       7.0   \n",
       "2                       30.0                1                       7.0   \n",
       "3                       30.0                1                       7.0   \n",
       "4                       30.0                1                       7.0   \n",
       "\n",
       "   fulladdress_pct_increase_0_to_7  address_count_1  fulladdress_count_1  \\\n",
       "0                              0.0                1                    1   \n",
       "1                              0.0                1                    1   \n",
       "2                              0.0                1                    1   \n",
       "3                              0.0                1                    1   \n",
       "4                              0.0                1                    1   \n",
       "\n",
       "   fulladdress_homephone_count_30  ...  ssn_name_dob_count_14  \\\n",
       "0                               1  ...                      1   \n",
       "1                               1  ...                      1   \n",
       "2                               1  ...                      1   \n",
       "3                               1  ...                      1   \n",
       "4                               1  ...                      1   \n",
       "\n",
       "   ssn_firstname_count_0_by_30  ssn_firstname_pct_increase_0_to_30  \\\n",
       "0                         30.0                                 0.0   \n",
       "1                         30.0                                 0.0   \n",
       "2                         30.0                                 0.0   \n",
       "3                         30.0                                 0.0   \n",
       "4                         30.0                                 0.0   \n",
       "\n",
       "   ssn_lastname_count_0_by_30  fulladdress_homephone_pct_increase_0_to_30  \\\n",
       "0                        30.0                                         0.0   \n",
       "1                        30.0                                         0.0   \n",
       "2                        30.0                                         0.0   \n",
       "3                        30.0                                         0.0   \n",
       "4                        30.0                                         0.0   \n",
       "\n",
       "   fulladdress_homephone_count_0_by_30  address_pct_increase_1_to_14  \\\n",
       "0                                 30.0                           0.0   \n",
       "1                                 30.0                           0.0   \n",
       "2                                 30.0                           0.0   \n",
       "3                                 30.0                           0.0   \n",
       "4                                 30.0                           0.0   \n",
       "\n",
       "   dob_count_wSame_homephone_7  name_count_wSame_homephone_7  fraud_label  \n",
       "0                            2                             2            0  \n",
       "1                            2                             2            1  \n",
       "2                            1                             1            0  \n",
       "3                            1                             1            0  \n",
       "4                            1                             1            0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T02:25:48.164403Z",
     "start_time": "2021-03-21T02:25:48.147448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T02:59:22.319241Z",
     "start_time": "2021-03-21T02:59:21.769279Z"
    }
   },
   "outputs": [],
   "source": [
    "Model=data.iloc[38511:833507,].copy()\n",
    "OOT=data.iloc[833507:,].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T02:39:35.694621Z",
     "start_time": "2021-03-25T02:39:34.000287Z"
    }
   },
   "outputs": [],
   "source": [
    "### 30 vars\n",
    "X_oot=OOT.iloc[:,:30].values\n",
    "y_oot=OOT.loc[:,'fraud_label'].values\n",
    "X=Model.iloc[:,:30].values\n",
    "y=Model.loc[:,'fraud_label'].values\n",
    "stdsc.fit(X)\n",
    "X=stdsc.transform(X)\n",
    "X_oot=stdsc.transform(X_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T02:39:57.027962Z",
     "start_time": "2021-03-25T02:39:56.992028Z"
    }
   },
   "outputs": [],
   "source": [
    "def NN_model(classifier,X,y,X_oot,y_oot):\n",
    "    start = timer()\n",
    "    N=10\n",
    "    FDR_train_30=np.zeros(N)\n",
    "    FDR_test_30=np.zeros(N)\n",
    "    FDR_oot_30=np.zeros(N)\n",
    "    i=0\n",
    "    kfold=StratifiedKFold(n_splits=10,shuffle=True)\n",
    "    for train, test in kfold.split(X, y):\n",
    "        X_train, X_test, y_train, y_test= X[train], X[test], y[train], y[test]\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred_tr=classifier.predict_proba(X_train)[:,1]\n",
    "        y_pred_ts=classifier.predict_proba(X_test)[:,1]\n",
    "        y_pred_oot=classifier.predict_proba(X_oot)[:,1]\n",
    "\n",
    "        train_temp=pd.DataFrame(columns=['y_train','y_pred_tr'])\n",
    "        Rows=round(len(y_train)*0.03)\n",
    "        train_temp['y_train']=y_train\n",
    "        train_temp['y_pred_tr']=y_pred_tr\n",
    "        train_temp.sort_values('y_pred_tr', ascending=False, inplace=True)\n",
    "        tempR=train_temp.head(Rows)\n",
    "        num=tempR.loc[:,'y_train']\n",
    "        den=((y_train==1).sum())\n",
    "        fdr_30_tr=sum(num)/den\n",
    "        FDR_train_30[i]=fdr_30_tr\n",
    "\n",
    "        test_temp=pd.DataFrame(columns=['y_test','y_pred_ts'])\n",
    "        Rows=round(len(y_test)*0.03)\n",
    "        test_temp['y_test']=y_test\n",
    "        test_temp['y_pred_ts']=y_pred_ts\n",
    "        test_temp.sort_values('y_pred_ts', ascending=False, inplace=True)\n",
    "        tempR=test_temp.head(Rows)\n",
    "        num=tempR.loc[:,'y_test']\n",
    "        den=((y_test==1).sum())\n",
    "        fdr_30_ts=sum(num)/den\n",
    "        FDR_test_30[i]=fdr_30_ts\n",
    "\n",
    "        oot_temp=pd.DataFrame(columns=['y_oot','y_pred_oot'])\n",
    "        Rows=round(len(y_oot)*0.03)\n",
    "        oot_temp['y_oot']=y_oot\n",
    "        oot_temp['y_pred_oot']=y_pred_oot\n",
    "        oot_temp.sort_values('y_pred_oot', ascending=False, inplace=True)\n",
    "        tempR=oot_temp.head(Rows)\n",
    "        num=tempR.loc[:,'y_oot']\n",
    "        den=((y_oot==1).sum())\n",
    "        fdr_30_oot=sum(num)/den\n",
    "        FDR_oot_30[i]=fdr_30_oot\n",
    "        i = i+1\n",
    "    \n",
    "    print(f'train:{FDR_train_30.mean()}')\n",
    "    print(f'test:{FDR_test_30.mean()}')\n",
    "    print(f'oot:{FDR_oot_30.mean()}')\n",
    "    print(f'Total run time{(timer()-start)/60:0.2f}min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-25T02:41:03.585Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(12,),max_iter=100)\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-25T02:41:04.266Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(15,),max_iter=100)\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-25T02:41:05.377Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(15,),max_iter=200)\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-25T02:41:25.685Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(20,),max_iter=150)\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-25T02:41:27.361Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(20,),max_iter=150, solver='sgd')\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-25T02:41:28.308Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(20,),max_iter=150, alpha=0.001)\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-25T02:41:31.467Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(20,),max_iter=150, activation='logistic')\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-25T02:44:26.998Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(20,),max_iter=150, activation='logistic',alpha=0.001)\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T05:36:16.478840Z",
     "start_time": "2021-03-21T05:29:42.430138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.5803394019679573\n",
      "test:0.580016405721685\n",
      "oot:0.562070410729254\n",
      "Total run time6.57min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(25,),max_iter=150)\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T05:43:01.537116Z",
     "start_time": "2021-03-21T05:36:16.902708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.5801266088851366\n",
      "test:0.5791459320784927\n",
      "oot:0.5622799664710814\n",
      "Total run time6.74min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(25,),max_iter=250)\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T05:49:56.652485Z",
     "start_time": "2021-03-21T05:43:01.966968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.5804458457657351\n",
      "test:0.5798418864457201\n",
      "oot:0.5621961441743503\n",
      "Total run time6.91min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(30,),max_iter=250)\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T06:06:13.259635Z",
     "start_time": "2021-03-21T05:59:11.483051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.5805619017893656\n",
      "test:0.5794936818260388\n",
      "oot:0.562699077954736\n",
      "Total run time7.03min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(30,),max_iter=300)\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T06:12:43.478605Z",
     "start_time": "2021-03-21T06:06:13.673492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.5801072833703084\n",
      "test:0.5781009391593356\n",
      "oot:0.5627409891031014\n",
      "Total run time6.50min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(25,),max_iter=300)\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T06:20:46.606021Z",
     "start_time": "2021-03-21T06:12:43.928370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.5804264865631994\n",
      "test:0.5797547784317828\n",
      "oot:0.5616512992455993\n",
      "Total run time8.04min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(40,),max_iter=400)\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T06:29:17.581909Z",
     "start_time": "2021-03-21T06:20:47.049793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.5803491180642415\n",
      "test:0.5788844564126358\n",
      "oot:0.5623218776194469\n",
      "Total run time8.51min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(50,),max_iter=500)\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T07:38:11.077581Z",
     "start_time": "2021-03-21T07:30:55.096006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.5799621529836275\n",
      "test:0.5792330400924299\n",
      "oot:0.5618608549874267\n",
      "Total run time7.27min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(30,),max_iter=500)\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T07:46:13.618077Z",
     "start_time": "2021-03-21T07:38:11.459526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.5801846135027107\n",
      "test:0.5791465385746732\n",
      "oot:0.5621123218776194\n",
      "Total run time8.04min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(25,),max_iter=500)\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T13:54:49.912110Z",
     "start_time": "2021-03-23T13:47:56.170042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.05980822\n",
      "Iteration 2, loss = 0.04428900\n",
      "Iteration 3, loss = 0.04379711\n",
      "Iteration 4, loss = 0.04359291\n",
      "Iteration 5, loss = 0.04348942\n",
      "Iteration 6, loss = 0.04338955\n",
      "Iteration 7, loss = 0.04325757\n",
      "Iteration 8, loss = 0.04323483\n",
      "Iteration 9, loss = 0.04323260\n",
      "Iteration 10, loss = 0.04316759\n",
      "Iteration 11, loss = 0.04311321\n",
      "Iteration 12, loss = 0.04310620\n",
      "Iteration 13, loss = 0.04306179\n",
      "Iteration 14, loss = 0.04306386\n",
      "Iteration 15, loss = 0.04302857\n",
      "Iteration 16, loss = 0.04305109\n",
      "Iteration 17, loss = 0.04301656\n",
      "Iteration 18, loss = 0.04297428\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.06181533\n",
      "Iteration 2, loss = 0.04378699\n",
      "Iteration 3, loss = 0.04344146\n",
      "Iteration 4, loss = 0.04329490\n",
      "Iteration 5, loss = 0.04317470\n",
      "Iteration 6, loss = 0.04309739\n",
      "Iteration 7, loss = 0.04301472\n",
      "Iteration 8, loss = 0.04297256\n",
      "Iteration 9, loss = 0.04294830\n",
      "Iteration 10, loss = 0.04289613\n",
      "Iteration 11, loss = 0.04290267\n",
      "Iteration 12, loss = 0.04288009\n",
      "Iteration 13, loss = 0.04280603\n",
      "Iteration 14, loss = 0.04281379\n",
      "Iteration 15, loss = 0.04280686\n",
      "Iteration 16, loss = 0.04276825\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.06172984\n",
      "Iteration 2, loss = 0.04425617\n",
      "Iteration 3, loss = 0.04386260\n",
      "Iteration 4, loss = 0.04367351\n",
      "Iteration 5, loss = 0.04360099\n",
      "Iteration 6, loss = 0.04349394\n",
      "Iteration 7, loss = 0.04344392\n",
      "Iteration 8, loss = 0.04340800\n",
      "Iteration 9, loss = 0.04335075\n",
      "Iteration 10, loss = 0.04332966\n",
      "Iteration 11, loss = 0.04329487\n",
      "Iteration 12, loss = 0.04327167\n",
      "Iteration 13, loss = 0.04326148\n",
      "Iteration 14, loss = 0.04325886\n",
      "Iteration 15, loss = 0.04323548\n",
      "Iteration 16, loss = 0.04325099\n",
      "Iteration 17, loss = 0.04323836\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.06619668\n",
      "Iteration 2, loss = 0.04390774\n",
      "Iteration 3, loss = 0.04359153\n",
      "Iteration 4, loss = 0.04342638\n",
      "Iteration 5, loss = 0.04332104\n",
      "Iteration 6, loss = 0.04329171\n",
      "Iteration 7, loss = 0.04317603\n",
      "Iteration 8, loss = 0.04317641\n",
      "Iteration 9, loss = 0.04313604\n",
      "Iteration 10, loss = 0.04309640\n",
      "Iteration 11, loss = 0.04307022\n",
      "Iteration 12, loss = 0.04304567\n",
      "Iteration 13, loss = 0.04299407\n",
      "Iteration 14, loss = 0.04296793\n",
      "Iteration 15, loss = 0.04296949\n",
      "Iteration 16, loss = 0.04296717\n",
      "Iteration 17, loss = 0.04289969\n",
      "Iteration 18, loss = 0.04291857\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.06965209\n",
      "Iteration 2, loss = 0.04430047\n",
      "Iteration 3, loss = 0.04394181\n",
      "Iteration 4, loss = 0.04377296\n",
      "Iteration 5, loss = 0.04370035\n",
      "Iteration 6, loss = 0.04361939\n",
      "Iteration 7, loss = 0.04357383\n",
      "Iteration 8, loss = 0.04345964\n",
      "Iteration 9, loss = 0.04344155\n",
      "Iteration 10, loss = 0.04338576\n",
      "Iteration 11, loss = 0.04336225\n",
      "Iteration 12, loss = 0.04330291\n",
      "Iteration 13, loss = 0.04329448\n",
      "Iteration 14, loss = 0.04329711\n",
      "Iteration 15, loss = 0.04325392\n",
      "Iteration 16, loss = 0.04324319\n",
      "Iteration 17, loss = 0.04324541\n",
      "Iteration 18, loss = 0.04319272\n",
      "Iteration 19, loss = 0.04318635\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.06666581\n",
      "Iteration 2, loss = 0.04447298\n",
      "Iteration 3, loss = 0.04400914\n",
      "Iteration 4, loss = 0.04389186\n",
      "Iteration 5, loss = 0.04377787\n",
      "Iteration 6, loss = 0.04373932\n",
      "Iteration 7, loss = 0.04367691\n",
      "Iteration 8, loss = 0.04363468\n",
      "Iteration 9, loss = 0.04358098\n",
      "Iteration 10, loss = 0.04355899\n",
      "Iteration 11, loss = 0.04351546\n",
      "Iteration 12, loss = 0.04352140\n",
      "Iteration 13, loss = 0.04346216\n",
      "Iteration 14, loss = 0.04346415\n",
      "Iteration 15, loss = 0.04342869\n",
      "Iteration 16, loss = 0.04341693\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.06113248\n",
      "Iteration 2, loss = 0.04446707\n",
      "Iteration 3, loss = 0.04402343\n",
      "Iteration 4, loss = 0.04382025\n",
      "Iteration 5, loss = 0.04368896\n",
      "Iteration 6, loss = 0.04361328\n",
      "Iteration 7, loss = 0.04355154\n",
      "Iteration 8, loss = 0.04347657\n",
      "Iteration 9, loss = 0.04341147\n",
      "Iteration 10, loss = 0.04338093\n",
      "Iteration 11, loss = 0.04333559\n",
      "Iteration 12, loss = 0.04331426\n",
      "Iteration 13, loss = 0.04331515\n",
      "Iteration 14, loss = 0.04327465\n",
      "Iteration 15, loss = 0.04326479\n",
      "Iteration 16, loss = 0.04325799\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07520644\n",
      "Iteration 2, loss = 0.04422273\n",
      "Iteration 3, loss = 0.04372250\n",
      "Iteration 4, loss = 0.04357910\n",
      "Iteration 5, loss = 0.04343436\n",
      "Iteration 6, loss = 0.04340887\n",
      "Iteration 7, loss = 0.04332533\n",
      "Iteration 8, loss = 0.04325803\n",
      "Iteration 9, loss = 0.04322733\n",
      "Iteration 10, loss = 0.04317467\n",
      "Iteration 11, loss = 0.04315392\n",
      "Iteration 12, loss = 0.04312472\n",
      "Iteration 13, loss = 0.04311017\n",
      "Iteration 14, loss = 0.04306170\n",
      "Iteration 15, loss = 0.04308323\n",
      "Iteration 16, loss = 0.04302986\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.06510996\n",
      "Iteration 2, loss = 0.04444632\n",
      "Iteration 3, loss = 0.04413256\n",
      "Iteration 4, loss = 0.04396823\n",
      "Iteration 5, loss = 0.04385109\n",
      "Iteration 6, loss = 0.04379808\n",
      "Iteration 7, loss = 0.04373263\n",
      "Iteration 8, loss = 0.04369854\n",
      "Iteration 9, loss = 0.04362294\n",
      "Iteration 10, loss = 0.04361790\n",
      "Iteration 11, loss = 0.04359920\n",
      "Iteration 12, loss = 0.04356092\n",
      "Iteration 13, loss = 0.04352336\n",
      "Iteration 14, loss = 0.04348873\n",
      "Iteration 15, loss = 0.04344000\n",
      "Iteration 16, loss = 0.04346735\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.05308444\n",
      "Iteration 2, loss = 0.04452043\n",
      "Iteration 3, loss = 0.04421863\n",
      "Iteration 4, loss = 0.04405220\n",
      "Iteration 5, loss = 0.04389581\n",
      "Iteration 6, loss = 0.04380349\n",
      "Iteration 7, loss = 0.04370815\n",
      "Iteration 8, loss = 0.04370190\n",
      "Iteration 9, loss = 0.04362673\n",
      "Iteration 10, loss = 0.04360276\n",
      "Iteration 11, loss = 0.04355661\n",
      "Iteration 12, loss = 0.04353324\n",
      "Iteration 13, loss = 0.04351985\n",
      "Iteration 14, loss = 0.04350218\n",
      "Iteration 15, loss = 0.04347603\n",
      "Iteration 16, loss = 0.04346726\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "train:0.5803781203730284\n",
      "test:0.5803638522211406\n",
      "oot:0.5620704107292539\n",
      "Total run time6.90min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(20,),max_iter=300, verbose=True)\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T14:00:48.403627Z",
     "start_time": "2021-03-23T13:54:51.385167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.5800395233541249\n",
      "test:0.5805382956850829\n",
      "oot:0.5614836546521376\n",
      "Total run time5.95min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(20,),max_iter=300, activation='logistic')\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T14:07:54.896525Z",
     "start_time": "2021-03-23T14:00:50.105043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.05977611\n",
      "Iteration 2, loss = 0.04415106\n",
      "Iteration 3, loss = 0.04366785\n",
      "Iteration 4, loss = 0.04351772\n",
      "Iteration 5, loss = 0.04333532\n",
      "Iteration 6, loss = 0.04323363\n",
      "Iteration 7, loss = 0.04315876\n",
      "Iteration 8, loss = 0.04308271\n",
      "Iteration 9, loss = 0.04306139\n",
      "Iteration 10, loss = 0.04300787\n",
      "Iteration 11, loss = 0.04297558\n",
      "Iteration 12, loss = 0.04292481\n",
      "Iteration 13, loss = 0.04291303\n",
      "Iteration 14, loss = 0.04291219\n",
      "Iteration 15, loss = 0.04288338\n",
      "Iteration 16, loss = 0.04288271\n",
      "Iteration 17, loss = 0.04285607\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.06061379\n",
      "Iteration 2, loss = 0.04391386\n",
      "Iteration 3, loss = 0.04346750\n",
      "Iteration 4, loss = 0.04327071\n",
      "Iteration 5, loss = 0.04314662\n",
      "Iteration 6, loss = 0.04307200\n",
      "Iteration 7, loss = 0.04294209\n",
      "Iteration 8, loss = 0.04286776\n",
      "Iteration 9, loss = 0.04283455\n",
      "Iteration 10, loss = 0.04276027\n",
      "Iteration 11, loss = 0.04274485\n",
      "Iteration 12, loss = 0.04271575\n",
      "Iteration 13, loss = 0.04271332\n",
      "Iteration 14, loss = 0.04266069\n",
      "Iteration 15, loss = 0.04265303\n",
      "Iteration 16, loss = 0.04265374\n",
      "Iteration 17, loss = 0.04260542\n",
      "Iteration 18, loss = 0.04258916\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.05995291\n",
      "Iteration 2, loss = 0.04414912\n",
      "Iteration 3, loss = 0.04386903\n",
      "Iteration 4, loss = 0.04374075\n",
      "Iteration 5, loss = 0.04363534\n",
      "Iteration 6, loss = 0.04356457\n",
      "Iteration 7, loss = 0.04345981\n",
      "Iteration 8, loss = 0.04342797\n",
      "Iteration 9, loss = 0.04337437\n",
      "Iteration 10, loss = 0.04336569\n",
      "Iteration 11, loss = 0.04331907\n",
      "Iteration 12, loss = 0.04329436\n",
      "Iteration 13, loss = 0.04330415\n",
      "Iteration 14, loss = 0.04326431\n",
      "Iteration 15, loss = 0.04326444\n",
      "Iteration 16, loss = 0.04322631\n",
      "Iteration 17, loss = 0.04320599\n",
      "Iteration 18, loss = 0.04318049\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.06131455\n",
      "Iteration 2, loss = 0.04428034\n",
      "Iteration 3, loss = 0.04392656\n",
      "Iteration 4, loss = 0.04374302\n",
      "Iteration 5, loss = 0.04361984\n",
      "Iteration 6, loss = 0.04353134\n",
      "Iteration 7, loss = 0.04341395\n",
      "Iteration 8, loss = 0.04331007\n",
      "Iteration 9, loss = 0.04331133\n",
      "Iteration 10, loss = 0.04322010\n",
      "Iteration 11, loss = 0.04318899\n",
      "Iteration 12, loss = 0.04315574\n",
      "Iteration 13, loss = 0.04313463\n",
      "Iteration 14, loss = 0.04313618\n",
      "Iteration 15, loss = 0.04307338\n",
      "Iteration 16, loss = 0.04303941\n",
      "Iteration 17, loss = 0.04299726\n",
      "Iteration 18, loss = 0.04297177\n",
      "Iteration 19, loss = 0.04300411\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.06265695\n",
      "Iteration 2, loss = 0.04440982\n",
      "Iteration 3, loss = 0.04396422\n",
      "Iteration 4, loss = 0.04376108\n",
      "Iteration 5, loss = 0.04368340\n",
      "Iteration 6, loss = 0.04359066\n",
      "Iteration 7, loss = 0.04349154\n",
      "Iteration 8, loss = 0.04346634\n",
      "Iteration 9, loss = 0.04343565\n",
      "Iteration 10, loss = 0.04339798\n",
      "Iteration 11, loss = 0.04335085\n",
      "Iteration 12, loss = 0.04332186\n",
      "Iteration 13, loss = 0.04329197\n",
      "Iteration 14, loss = 0.04328813\n",
      "Iteration 15, loss = 0.04319701\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.05549108\n",
      "Iteration 2, loss = 0.04445881\n",
      "Iteration 3, loss = 0.04406264\n",
      "Iteration 4, loss = 0.04389156\n",
      "Iteration 5, loss = 0.04381666\n",
      "Iteration 6, loss = 0.04372607\n",
      "Iteration 7, loss = 0.04364147\n",
      "Iteration 8, loss = 0.04362133\n",
      "Iteration 9, loss = 0.04354291\n",
      "Iteration 10, loss = 0.04354547\n",
      "Iteration 11, loss = 0.04347404\n",
      "Iteration 12, loss = 0.04346537\n",
      "Iteration 13, loss = 0.04344793\n",
      "Iteration 14, loss = 0.04341338\n",
      "Iteration 15, loss = 0.04338582\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.06137290\n",
      "Iteration 2, loss = 0.04456170\n",
      "Iteration 3, loss = 0.04420214\n",
      "Iteration 4, loss = 0.04399338\n",
      "Iteration 5, loss = 0.04388589\n",
      "Iteration 6, loss = 0.04378012\n",
      "Iteration 7, loss = 0.04372951\n",
      "Iteration 8, loss = 0.04366641\n",
      "Iteration 9, loss = 0.04362250\n",
      "Iteration 10, loss = 0.04356786\n",
      "Iteration 11, loss = 0.04355543\n",
      "Iteration 12, loss = 0.04350607\n",
      "Iteration 13, loss = 0.04346982\n",
      "Iteration 14, loss = 0.04342575\n",
      "Iteration 15, loss = 0.04341184\n",
      "Iteration 16, loss = 0.04337346\n",
      "Iteration 17, loss = 0.04336460\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.05586582\n",
      "Iteration 2, loss = 0.04392568\n",
      "Iteration 3, loss = 0.04368866\n",
      "Iteration 4, loss = 0.04349806\n",
      "Iteration 5, loss = 0.04342048\n",
      "Iteration 6, loss = 0.04334023\n",
      "Iteration 7, loss = 0.04328035\n",
      "Iteration 8, loss = 0.04323232\n",
      "Iteration 9, loss = 0.04319714\n",
      "Iteration 10, loss = 0.04315678\n",
      "Iteration 11, loss = 0.04317151\n",
      "Iteration 12, loss = 0.04310990\n",
      "Iteration 13, loss = 0.04312756\n",
      "Iteration 14, loss = 0.04307445\n",
      "Iteration 15, loss = 0.04305859\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.05605471\n",
      "Iteration 2, loss = 0.04444935\n",
      "Iteration 3, loss = 0.04405692\n",
      "Iteration 4, loss = 0.04385210\n",
      "Iteration 5, loss = 0.04376689\n",
      "Iteration 6, loss = 0.04366231\n",
      "Iteration 7, loss = 0.04365075\n",
      "Iteration 8, loss = 0.04358001\n",
      "Iteration 9, loss = 0.04357439\n",
      "Iteration 10, loss = 0.04352968\n",
      "Iteration 11, loss = 0.04349090\n",
      "Iteration 12, loss = 0.04348478\n",
      "Iteration 13, loss = 0.04346203\n",
      "Iteration 14, loss = 0.04341985\n",
      "Iteration 15, loss = 0.04342068\n",
      "Iteration 16, loss = 0.04342144\n",
      "Iteration 17, loss = 0.04338060\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.05697903\n",
      "Iteration 2, loss = 0.04438923\n",
      "Iteration 3, loss = 0.04403341\n",
      "Iteration 4, loss = 0.04390216\n",
      "Iteration 5, loss = 0.04378349\n",
      "Iteration 6, loss = 0.04368822\n",
      "Iteration 7, loss = 0.04359916\n",
      "Iteration 8, loss = 0.04358283\n",
      "Iteration 9, loss = 0.04352636\n",
      "Iteration 10, loss = 0.04345472\n",
      "Iteration 11, loss = 0.04344998\n",
      "Iteration 12, loss = 0.04341954\n",
      "Iteration 13, loss = 0.04335703\n",
      "Iteration 14, loss = 0.04337366\n",
      "Iteration 15, loss = 0.04329806\n",
      "Iteration 16, loss = 0.04327893\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "train:0.5800782426949658\n",
      "test:0.578709937136671\n",
      "oot:0.5623637887678122\n",
      "Total run time7.08min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(25,),max_iter=400, verbose=True)\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T14:13:45.614183Z",
     "start_time": "2021-03-23T14:07:56.781478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.5799331244732905\n",
      "test:0.5788837741044326\n",
      "oot:0.5608968985750209\n",
      "Total run time5.81min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(25,),max_iter=400, activation='logistic')\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T14:21:04.407239Z",
     "start_time": "2021-03-23T14:13:47.104238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.05670596\n",
      "Iteration 2, loss = 0.04390501\n",
      "Iteration 3, loss = 0.04357649\n",
      "Iteration 4, loss = 0.04344503\n",
      "Iteration 5, loss = 0.04331160\n",
      "Iteration 6, loss = 0.04323474\n",
      "Iteration 7, loss = 0.04318646\n",
      "Iteration 8, loss = 0.04312283\n",
      "Iteration 9, loss = 0.04308309\n",
      "Iteration 10, loss = 0.04304643\n",
      "Iteration 11, loss = 0.04299109\n",
      "Iteration 12, loss = 0.04294676\n",
      "Iteration 13, loss = 0.04294650\n",
      "Iteration 14, loss = 0.04289376\n",
      "Iteration 15, loss = 0.04291677\n",
      "Iteration 16, loss = 0.04288648\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.05541095\n",
      "Iteration 2, loss = 0.04363404\n",
      "Iteration 3, loss = 0.04323805\n",
      "Iteration 4, loss = 0.04313232\n",
      "Iteration 5, loss = 0.04302893\n",
      "Iteration 6, loss = 0.04294210\n",
      "Iteration 7, loss = 0.04287358\n",
      "Iteration 8, loss = 0.04284802\n",
      "Iteration 9, loss = 0.04279123\n",
      "Iteration 10, loss = 0.04273862\n",
      "Iteration 11, loss = 0.04275710\n",
      "Iteration 12, loss = 0.04268806\n",
      "Iteration 13, loss = 0.04270218\n",
      "Iteration 14, loss = 0.04266721\n",
      "Iteration 15, loss = 0.04265494\n",
      "Iteration 16, loss = 0.04260598\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.06911582\n",
      "Iteration 2, loss = 0.04434360\n",
      "Iteration 3, loss = 0.04402391\n",
      "Iteration 4, loss = 0.04390680\n",
      "Iteration 5, loss = 0.04382017\n",
      "Iteration 6, loss = 0.04371437\n",
      "Iteration 7, loss = 0.04366276\n",
      "Iteration 8, loss = 0.04359392\n",
      "Iteration 9, loss = 0.04353153\n",
      "Iteration 10, loss = 0.04346753\n",
      "Iteration 11, loss = 0.04345013\n",
      "Iteration 12, loss = 0.04344734\n",
      "Iteration 13, loss = 0.04339740\n",
      "Iteration 14, loss = 0.04340403\n",
      "Iteration 15, loss = 0.04337315\n",
      "Iteration 16, loss = 0.04333244\n",
      "Iteration 17, loss = 0.04330969\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.05814249\n",
      "Iteration 2, loss = 0.04408564\n",
      "Iteration 3, loss = 0.04369445\n",
      "Iteration 4, loss = 0.04353157\n",
      "Iteration 5, loss = 0.04344109\n",
      "Iteration 6, loss = 0.04333314\n",
      "Iteration 7, loss = 0.04326165\n",
      "Iteration 8, loss = 0.04322527\n",
      "Iteration 9, loss = 0.04314713\n",
      "Iteration 10, loss = 0.04311437\n",
      "Iteration 11, loss = 0.04308200\n",
      "Iteration 12, loss = 0.04302474\n",
      "Iteration 13, loss = 0.04303410\n",
      "Iteration 14, loss = 0.04302889\n",
      "Iteration 15, loss = 0.04298453\n",
      "Iteration 16, loss = 0.04298424\n",
      "Iteration 17, loss = 0.04298152\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.06092465\n",
      "Iteration 2, loss = 0.04421710\n",
      "Iteration 3, loss = 0.04389143\n",
      "Iteration 4, loss = 0.04373498\n",
      "Iteration 5, loss = 0.04363029\n",
      "Iteration 6, loss = 0.04360446\n",
      "Iteration 7, loss = 0.04347463\n",
      "Iteration 8, loss = 0.04342896\n",
      "Iteration 9, loss = 0.04336913\n",
      "Iteration 10, loss = 0.04333089\n",
      "Iteration 11, loss = 0.04330538\n",
      "Iteration 12, loss = 0.04327917\n",
      "Iteration 13, loss = 0.04324959\n",
      "Iteration 14, loss = 0.04321667\n",
      "Iteration 15, loss = 0.04320525\n",
      "Iteration 16, loss = 0.04316610\n",
      "Iteration 17, loss = 0.04313732\n",
      "Iteration 18, loss = 0.04311676\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.06629249\n",
      "Iteration 2, loss = 0.04455920\n",
      "Iteration 3, loss = 0.04419922\n",
      "Iteration 4, loss = 0.04395568\n",
      "Iteration 5, loss = 0.04382857\n",
      "Iteration 6, loss = 0.04372426\n",
      "Iteration 7, loss = 0.04364588\n",
      "Iteration 8, loss = 0.04358617\n",
      "Iteration 9, loss = 0.04352332\n",
      "Iteration 10, loss = 0.04348067\n",
      "Iteration 11, loss = 0.04347435\n",
      "Iteration 12, loss = 0.04342109\n",
      "Iteration 13, loss = 0.04339102\n",
      "Iteration 14, loss = 0.04336138\n",
      "Iteration 15, loss = 0.04334383\n",
      "Iteration 16, loss = 0.04331765\n",
      "Iteration 17, loss = 0.04332163\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.05993817\n",
      "Iteration 2, loss = 0.04431042\n",
      "Iteration 3, loss = 0.04395514\n",
      "Iteration 4, loss = 0.04384668\n",
      "Iteration 5, loss = 0.04376186\n",
      "Iteration 6, loss = 0.04366138\n",
      "Iteration 7, loss = 0.04362633\n",
      "Iteration 8, loss = 0.04357614\n",
      "Iteration 9, loss = 0.04349925\n",
      "Iteration 10, loss = 0.04348967\n",
      "Iteration 11, loss = 0.04344090\n",
      "Iteration 12, loss = 0.04342049\n",
      "Iteration 13, loss = 0.04337932\n",
      "Iteration 14, loss = 0.04335721\n",
      "Iteration 15, loss = 0.04335452\n",
      "Iteration 16, loss = 0.04332171\n",
      "Iteration 17, loss = 0.04330662\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07450556\n",
      "Iteration 2, loss = 0.04422671\n",
      "Iteration 3, loss = 0.04379498\n",
      "Iteration 4, loss = 0.04367497\n",
      "Iteration 5, loss = 0.04350820\n",
      "Iteration 6, loss = 0.04343420\n",
      "Iteration 7, loss = 0.04336668\n",
      "Iteration 8, loss = 0.04329839\n",
      "Iteration 9, loss = 0.04328722\n",
      "Iteration 10, loss = 0.04323780\n",
      "Iteration 11, loss = 0.04324928\n",
      "Iteration 12, loss = 0.04316203\n",
      "Iteration 13, loss = 0.04318751\n",
      "Iteration 14, loss = 0.04315435\n",
      "Iteration 15, loss = 0.04314756\n",
      "Iteration 16, loss = 0.04310180\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.05480857\n",
      "Iteration 2, loss = 0.04448393\n",
      "Iteration 3, loss = 0.04408699\n",
      "Iteration 4, loss = 0.04392446\n",
      "Iteration 5, loss = 0.04385102\n",
      "Iteration 6, loss = 0.04372674\n",
      "Iteration 7, loss = 0.04371982\n",
      "Iteration 8, loss = 0.04364196\n",
      "Iteration 9, loss = 0.04360445\n",
      "Iteration 10, loss = 0.04356277\n",
      "Iteration 11, loss = 0.04351542\n",
      "Iteration 12, loss = 0.04352582\n",
      "Iteration 13, loss = 0.04347289\n",
      "Iteration 14, loss = 0.04343362\n",
      "Iteration 15, loss = 0.04341180\n",
      "Iteration 16, loss = 0.04338435\n",
      "Iteration 17, loss = 0.04337623\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.05623731\n",
      "Iteration 2, loss = 0.04412978\n",
      "Iteration 3, loss = 0.04383595\n",
      "Iteration 4, loss = 0.04367822\n",
      "Iteration 5, loss = 0.04357509\n",
      "Iteration 6, loss = 0.04350673\n",
      "Iteration 7, loss = 0.04346892\n",
      "Iteration 8, loss = 0.04340661\n",
      "Iteration 9, loss = 0.04337080\n",
      "Iteration 10, loss = 0.04334990\n",
      "Iteration 11, loss = 0.04331078\n",
      "Iteration 12, loss = 0.04328858\n",
      "Iteration 13, loss = 0.04326507\n",
      "Iteration 14, loss = 0.04324745\n",
      "Iteration 15, loss = 0.04322934\n",
      "Iteration 16, loss = 0.04322183\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "train:0.5808134179561057\n",
      "test:0.5801034379235996\n",
      "oot:0.5624895222129087\n",
      "Total run time7.29min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(30,),max_iter=500, verbose=True)\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T14:27:12.505398Z",
     "start_time": "2021-03-23T14:21:05.889240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.5802330058944317\n",
      "test:0.5799291460837026\n",
      "oot:0.5606035205364627\n",
      "Total run time6.11min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(30,),max_iter=500, activation='logistic')\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:08:18.884312Z",
     "start_time": "2021-03-24T06:59:59.942185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.5626850435356536\n",
      "test:0.5627752355479541\n",
      "oot:0.5371332774518022\n",
      "Total run time8.32min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(20,),max_iter=300, activation='logistic',solver='sgd')\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:22:55.396652Z",
     "start_time": "2021-03-24T07:17:12.452196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.57960421922066\n",
      "test:0.5787964386544275\n",
      "oot:0.5598072087175189\n",
      "Total run time5.72min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(20,),max_iter=150, activation='logistic', alpha=0.001)\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:28:35.325257Z",
     "start_time": "2021-03-24T07:22:57.248700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.5793333672456256\n",
      "test:0.5792321303481591\n",
      "oot:0.5593880972338642\n",
      "Total run time5.63min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(20,),max_iter=300, activation='logistic', alpha=0.001)\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:37:26.294843Z",
     "start_time": "2021-03-24T07:31:56.815386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.5798267255924558\n",
      "test:0.5796672913577325\n",
      "oot:0.5613998323554066\n",
      "Total run time5.49min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(20,),max_iter=300, activation='logistic')\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:45:49.641906Z",
     "start_time": "2021-03-24T07:39:44.767641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.5801943164982197\n",
      "test:0.5794931511418806\n",
      "oot:0.5613998323554065\n",
      "Total run time6.08min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(20,),max_iter=300, activation='logistic')\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:52:38.521004Z",
     "start_time": "2021-03-24T07:45:51.497942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.5796332720610081\n",
      "test:0.5793194657981642\n",
      "oot:0.5611064543168484\n",
      "Total run time6.78min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(20,),max_iter=300)\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T08:08:34.823744Z",
     "start_time": "2021-03-21T08:08:33.856266Z"
    }
   },
   "outputs": [],
   "source": [
    "### 25 vars\n",
    "X_oot=OOT.iloc[:,:25].values\n",
    "y_oot=OOT.loc[:,'fraud_label'].values\n",
    "X=Model.iloc[:,:25].values\n",
    "y=Model.loc[:,'fraud_label'].values\n",
    "stdsc.fit(X)\n",
    "X=stdsc.transform(X)\n",
    "X_oot=stdsc.transform(X_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T08:16:00.449335Z",
     "start_time": "2021-03-21T08:09:15.389069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.5387913183708631\n",
      "test:0.5382292737511485\n",
      "oot:0.525859178541492\n",
      "Total run time6.75min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(25,),max_iter=300)\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T08:22:25.837204Z",
     "start_time": "2021-03-21T08:16:01.126490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.5386848970315572\n",
      "test:0.5378808416953993\n",
      "oot:0.5258172673931266\n",
      "Total run time6.41min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(20,),max_iter=300)\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:01:35.733870Z",
     "start_time": "2021-03-23T14:56:04.630696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.5386074845514257\n",
      "test:0.5378810691314672\n",
      "oot:0.52476948868399\n",
      "Total run time5.52min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(15,),max_iter=250)\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:06:54.663580Z",
     "start_time": "2021-03-23T15:01:37.273718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.538897703215153\n",
      "test:0.5376201241497682\n",
      "oot:0.5259010896898576\n",
      "Total run time5.29min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(15,),max_iter=250, activation='logistic')\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:12:15.022437Z",
     "start_time": "2021-03-23T15:06:56.124684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.5393620311801068\n",
      "test:0.537794112741575\n",
      "oot:0.5256915339480301\n",
      "Total run time5.31min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(20,),max_iter=300, activation='logistic')\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:18:27.241606Z",
     "start_time": "2021-03-23T15:12:16.563355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.5388686793836639\n",
      "test:0.5377072321637055\n",
      "oot:0.5259849119865884\n",
      "Total run time6.18min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(25,),max_iter=400)\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:23:57.141933Z",
     "start_time": "2021-03-23T15:18:28.771482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.5390524739007763\n",
      "test:0.5377942643656202\n",
      "oot:0.5255658005029338\n",
      "Total run time5.47min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(25,),max_iter=400, activation='logistic')\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:30:33.601215Z",
     "start_time": "2021-03-23T15:23:58.635937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.538955750878131\n",
      "test:0.5370972486300768\n",
      "oot:0.5251886001676446\n",
      "Total run time6.58min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(30,),max_iter=500)\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:36:09.510497Z",
     "start_time": "2021-03-23T15:30:35.114200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.5393813857037941\n",
      "test:0.5385777058068977\n",
      "oot:0.5258172673931265\n",
      "Total run time5.57min\n"
     ]
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(30,),max_iter=500, activation='logistic')\n",
    "NN_model(classifier,X,y,X_oot,y_oot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
